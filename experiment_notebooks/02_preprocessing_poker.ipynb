{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as scp\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import os\n",
    "\n",
    "ROOT = os.path.dirname(os.getcwd())\n",
    "train_data = pd.read_csv(os.path.join(ROOT, 'data', 'pokerhands', 'train.csv'))\n",
    "test_data = pd.read_csv(os.path.join(ROOT, 'data', 'pokerhands', 'test.csv'))\n",
    "test_data_correct = pd.read_csv(os.path.join(ROOT, 'data', 'pokerhands', 'test_correct.csv'))\n",
    "\n",
    "test_data = test_data.head(10000)\n",
    "test_data_correct = test_data_correct.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(df):\n",
    "    df['min-flush'] = (df['S1']==df['S2'])&(df['S2']==df['S3'])&(df['S3']==df['S4'])&(df['S4']==df['S5'])\n",
    "    a1 = df[['C1', 'C2', 'C3', 'C4', 'C5']].min(axis = 1)\n",
    "    b1 = 5 * a1 + 10\n",
    "    a2 = df[['C1', 'C2', 'C3', 'C4', 'C5']].max(axis = 1).apply(scp.math.factorial)\n",
    "    b2 = (df[['C1', 'C2', 'C3', 'C4', 'C5']].min(axis = 1) - 1).apply(scp.math.factorial)\n",
    "    c = a2/b2\n",
    "    df['min-straight'] = ((df['C1']*df['C2']*df['C3']*df['C4']*df['C5'] == c) & (df['C1']+df['C2']+df['C3']+df['C4']+df['C5'] == b1)) | ( (df[['C1', 'C2', 'C3', 'C4', 'C5']].min(axis = 1) == 1) & (df['C1']*df['C2']*df['C3']*df['C4']*df['C5'] == 17160))\n",
    "    df['min - straight flush'] = df['min-flush'] & df['min-straight']\n",
    "    df['RF'] = df[df['min - straight flush'] == True][['C1', 'C2', 'C3', 'C4', 'C5']].sum(axis = 1) == 47\n",
    "    df['RF'] = df['RF'].fillna(False)\n",
    "    df['straight flush'] = (df['min - straight flush'] == True) & (df['RF'] == False)\n",
    "    df['straight flush'] = df['straight flush'].fillna(False)\n",
    "    df = df.drop('min - straight flush', axis = 1)\n",
    "    df['flush'] = (df['straight flush'] == False) & (df['min-flush'] == True) & (df['RF'] == False)\n",
    "    df['straight'] = (df['straight flush'] == False) & (df['min-straight'] == True) & (df['RF'] == False)\n",
    "    df = df.drop('min-straight', axis = 1)\n",
    "    df = df.drop('min-flush', axis = 1)\n",
    "    df['flush'] = df['flush'].fillna(False)\n",
    "    df['straight'] = df['straight'].fillna(False)\n",
    "    df['Nothing in hand'] = (df[['C1', 'C2', 'C3', 'C4', 'C5']].nunique(axis = 1) == 5) & (df['straight'] == False) & (df['flush'] == False) & (df['RF'] == False)& (df['straight flush'] == False) \n",
    "    df['Nothing in hand'] = df['Nothing in hand'].fillna(False)\n",
    "    df['One pair'] = (df[['C1', 'C2', 'C3', 'C4', 'C5']].nunique(axis = 1) == 4)\n",
    "    df['One pair'] = df['One pair'].fillna(False)\n",
    "    df['Four of a kind or Full house'] = df[['C1', 'C2', 'C3', 'C4', 'C5']].nunique(axis = 1) == 2\n",
    "    df['Two pairs or Three of a kind'] = df[['C1', 'C2', 'C3', 'C4', 'C5']].nunique(axis = 1) == 3\n",
    "    df['Four of a kind or Full house'] = df['Four of a kind or Full house'].fillna(False)\n",
    "    df['Two pairs or Three of a kind'] = df['Two pairs or Three of a kind'].fillna(False)\n",
    "    dff = np.array(df[['C1', 'C2', 'C3', 'C4', 'C5']])\n",
    "    a = []\n",
    "    for i in range(dff.shape[0]):\n",
    "        u, v  = np.unique(dff[i], return_counts=True)\n",
    "        a.append(4 in v)\n",
    "    df['Four of a kind'] = np.array(a)\n",
    "    df['Full house'] = (df['Four of a kind']==False) & (df['Four of a kind or Full house'] ==True)\n",
    "    df = df.drop('Four of a kind or Full house', axis =1)\n",
    "    a = []\n",
    "    for i in range(dff.shape[0]):\n",
    "        u, v  = np.unique(dff[i], return_counts=True)\n",
    "        a.append(set(v) == set([1,1,3]))\n",
    "    df['Three of a kind'] = np.array(a)\n",
    "    df['Two pairs'] = (df['Three of a kind']==False) & (df['Two pairs or Three of a kind'] ==True)\n",
    "    df = df.drop('Two pairs or Three of a kind', axis =1)\n",
    "    df = df.drop(['S1', 'S2','S3','S4','S5','C1','C2','C3','C4','C5'], axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df = preproc(train_data)\n",
    "train_df = train_data\n",
    "\n",
    "x = train_df.drop('hand', axis =1)\n",
    "y = train_df['hand']\n",
    "x = np.array(x).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(x, y)\n",
    "x_test = test_data\n",
    "x_test = x_test.drop('id', axis = 1)\n",
    "#x_test = preproc(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id              0.618\n",
      "hand_predict    0.618\n",
      "id              0.618\n",
      "hand            0.618\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array(x_test).astype(int)\n",
    "predictions = model.predict(x_test).astype(int)\n",
    "output = pd.DataFrame({'id': test_data.id, 'hand_predict': predictions})\n",
    "\n",
    "output = pd.concat([output, test_data_correct], axis=1)\n",
    "correct = output[(output['hand'] == output['hand_predict'])].count()\n",
    "print(correct / 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:10:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\musta\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost: id              0.7298\n",
      "hand_predict    0.7298\n",
      "id              0.7298\n",
      "hand            0.7298\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(x, y)\n",
    "x_test = test_data\n",
    "x_test = x_test.drop('id', axis = 1)\n",
    "#x_test = preproc(x_test)\n",
    "\n",
    "x_test = np.array(x_test).astype(int)\n",
    "predictions = model.predict(x_test).astype(int)\n",
    "output = pd.DataFrame({'id': test_data.id, 'hand_predict': predictions})\n",
    "\n",
    "output = pd.concat([output, test_data_correct], axis=1)\n",
    "correct = output[(output['hand'] == output['hand_predict'])].count()\n",
    "print(\"XGBoost:\", correct / 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
