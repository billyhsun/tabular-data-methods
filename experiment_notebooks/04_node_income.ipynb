{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NODE_tabular_adult_income.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsr4aN9VzJVd"
      },
      "source": [
        "# Description\n",
        "\n",
        "Training and hypertuning NODE for tabular data\n",
        "\n",
        "Referenced from the blog post about NODE and CatBoost on [Follow the Data](https://followthedata.wordpress.com/modelling-tabular-data-with-catboost-and-node)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxoE-ggD6ZGS"
      },
      "source": [
        "import math\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Fca2uSR6leC"
      },
      "source": [
        "##Clone the NODE repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PFlIMyP6Boa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98c7f3de-6ea3-4314-846d-646e4679a11c"
      },
      "source": [
        "!git clone https://github.com/Qwicen/node.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'node'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 33 (delta 8), reused 17 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (33/33), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjLiSSYG6XuU"
      },
      "source": [
        "os.chdir('node')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1Y8eDvY6sdb"
      },
      "source": [
        "## Install the dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBAJ3TSu6GSP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "410b3fc5-848d-498c-9736-966ea7f26a8b"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/facebookresearch/qhoptim/archive/master.zip (from -r requirements.txt (line 14))\n",
            "\u001b[?25l  Downloading https://github.com/facebookresearch/qhoptim/archive/master.zip\n",
            "\u001b[K     | 7.6MB 13.9MB/s\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy>=0.13 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.17 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.22.2.post1)\n",
            "Collecting catboost==0.12.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/f0/eeb5f36d9cde07d162c0d1a05d2d6a788be71cda0d8b77dd89841de40819/catboost-0.12.2-cp37-none-manylinux1_x86_64.whl (55.4MB)\n",
            "\u001b[K     |████████████████████████████████| 55.4MB 53kB/s \n",
            "\u001b[?25hCollecting xgboost==0.81\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/21/8b2ec99862903a6d3aed62ce156d21d114b8666e669c46d9e54041df9496/xgboost-0.81-py2.py3-none-manylinux1_x86_64.whl (16.6MB)\n",
            "\u001b[K     |████████████████████████████████| 16.6MB 216kB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (3.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (4.41.1)\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 60.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.1.5)\n",
            "Requirement already satisfied: prefetch_generator in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (2.23.0)\n",
            "Collecting category_encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/57/fcef41c248701ee62e8325026b90c432adea35555cbc870aff9cfba23727/category_encoders-2.2.2-py2.py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1.0->-r requirements.txt (line 1)) (3.7.4.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.17->-r requirements.txt (line 4)) (1.0.1)\n",
            "Collecting enum34\n",
            "  Downloading https://files.pythonhosted.org/packages/63/f6/ccb1c83687756aeabbf3ca0f213508fcfb03883ff200d201b3a4c60cedcc/enum34-1.1.10-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost==0.12.2->-r requirements.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 7)) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 7)) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 7)) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX->-r requirements.txt (line 9)) (3.12.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 10)) (2018.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 12)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 12)) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 12)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 12)) (3.0.4)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders->-r requirements.txt (line 13)) (0.10.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders->-r requirements.txt (line 13)) (0.5.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX->-r requirements.txt (line 9)) (54.2.0)\n",
            "Building wheels for collected packages: qhoptim\n",
            "  Building wheel for qhoptim (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for qhoptim: filename=qhoptim-1.1.0-cp37-none-any.whl size=20327 sha256=4504d284b92d5dac0981232d60f2a5406ee4aef91ab1092b2013cce139a57277\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-px8mmco7/wheels/63/53/2b/3b721f6feacd39063f6300e890b7cf633910a33e7b996edbd3\n",
            "Successfully built qhoptim\n",
            "Installing collected packages: enum34, catboost, xgboost, tensorboardX, category-encoders, qhoptim\n",
            "  Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "Successfully installed catboost-0.12.2 category-encoders-2.2.2 enum34-1.1.10 qhoptim-1.1.0 tensorboardX-2.2 xgboost-0.81\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "enum"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9gEBEaroaCG"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajHf8Pm2657q"
      },
      "source": [
        "## Load, split and preprocess the data.\n",
        "\n",
        "Owing to the time it takes to train a NODE model, we will not use k-fold cross validation as we did in the [CatBoost/logistic regression notebook](https://) but simply use a train/test split.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aobDox2y6H3m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0446feb7-8e56-450e-b58a-8f6c83f928cb"
      },
      "source": [
        "from category_encoders import LeaveOneOutEncoder\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('https://docs.google.com/uc?id=10eFO2rVlsQBUffn0b7UCAp28n0mkLCy7&export=download')\n",
        "labels = df.pop('<=50K')\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(df, labels, test_size=0.2)\n",
        " \n",
        "class_to_int = {c: i for i, c in enumerate(y_train.unique())}                                                                                                               \n",
        "y_train_int = [class_to_int[v] for v in y_train]                                                                                                                            \n",
        "y_val_int = [class_to_int[v] for v in y_val] \n",
        "\n",
        "cat_features = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']  \n",
        "\n",
        "cat_encoder = LeaveOneOutEncoder()\n",
        "cat_encoder.fit(X_train[cat_features], y_train_int)\n",
        "X_train[cat_features] = cat_encoder.transform(X_train[cat_features])\n",
        "X_val[cat_features] = cat_encoder.transform(X_val[cat_features])\n",
        "\n",
        "# Node is going to want to have the values as float32 at some points\n",
        "X_train = X_train.values.astype('float32')\n",
        "X_val = X_val.values.astype('float32')\n",
        "y_train = np.array(y_train_int)\n",
        "y_val = np.array(y_val_int)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3069: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[k1] = value[k2]\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3069: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[k1] = value[k2]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pgvXe3u7a2S"
      },
      "source": [
        "Now we have a fully numeric dataset, and we can start using the NODE functionality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPVWqQXA7CSC"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "from qhoptim.pyt import QHAdam\n",
        "import torch, torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "# We access the NODE functionality through the lib/ subfolder.\n",
        "import lib \n",
        "%matplotlib inline"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4QMoBFC7NAO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40eeee10-e660-45c2-d2ed-48c0568afa64"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device}')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWcfppKI8jBb"
      },
      "source": [
        "Initialize a NODE model. There are some parameters here to be aware of:\n",
        "\n",
        "- layer_dim (how many \"trees\" should be used in each layer)\n",
        "- num_layers (how many layers, i.e. how many stacked tree ensembles)\n",
        "- depth (how many levels should each tree have)\n",
        "\n",
        "I am not sure what the significance of 'flatten_output' is. In the example notebook, they set the tree_dim to no_classes+1, but here I do not add 1. The 'choice_function' and 'bin_function' parameters should be left as is. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX6gTcU99E27"
      },
      "source": [
        "num_features = X_train.shape[1]\n",
        "num_classes = len(set(y_train))\n",
        "ts = math.floor(time.time())\n",
        "experiment_name = f'node_adult_{ts}'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nD3PRZ575BP"
      },
      "source": [
        "model = nn.Sequential(\n",
        "    lib.DenseBlock(num_features,\n",
        "                   layer_dim=128,\n",
        "                   num_layers=8,\n",
        "                   tree_dim=num_classes,\n",
        "                   flatten_output=False,\n",
        "                   depth=6,\n",
        "                   choice_function=lib.entmax15,\n",
        "                   bin_function=lib.entmoid15),\n",
        "    lib.Lambda(lambda x: x[..., :num_classes].mean(dim=-2)),\n",
        ").to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    res = model(torch.as_tensor(X_train[:2000], device=device))\n",
        "    # trigger data-aware init"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z93FeDtR_4og"
      },
      "source": [
        "## Initialize a Trainer object.\n",
        "\n",
        "This is a class that the NODE authors wrote to help take care of the training process. You may prefer to write your own training loop in Pytorch instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQcUy8t976UJ"
      },
      "source": [
        "trainer = lib.Trainer(\n",
        "    model=model, loss_function=F.cross_entropy,\n",
        "    experiment_name=experiment_name+'_extra_2',\n",
        "    warm_start=False,\n",
        "    Optimizer=QHAdam,\n",
        "    optimizer_params=dict(nus=(0.7, 1.0), betas=(0.95, 0.998)),\n",
        "    verbose=True,\n",
        "    n_last_checkpoints=5\n",
        ")"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Iu71XlmAJx-"
      },
      "source": [
        "## Define parameters for the training loop.\n",
        "\n",
        "Let's use 2500 batches as the early stopping criterion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0Jm95M_ADjB"
      },
      "source": [
        "loss_history, err_history = [], []\n",
        "best_val_err = 1.0\n",
        "best_step = 0\n",
        "early_stopping_rounds = 2500\n",
        "report_frequency = 50"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m848we_zz9-O"
      },
      "source": [],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2asZe1JT67Y",
        "outputId": "6fa7d8db-1c8a-441b-aa90-23983687eae1"
      },
      "source": [
        "X_train.shape[0]"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26048"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZqaETe8Ag-X"
      },
      "source": [
        "This training loop is taken from the example notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-YUOd6FAR1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e3e7142-6a94-4ef5-dcf9-6462a19b57f0"
      },
      "source": [
        "train_acc, test_acc = [], []\n",
        "\n",
        "for batch in lib.iterate_minibatches(X_train,\n",
        "                                     y_train,\n",
        "                                     batch_size=512, \n",
        "                                     shuffle=True,\n",
        "                                     epochs=1000):\n",
        "    metrics = trainer.train_on_batch(*batch, device=device)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    if trainer.step % report_frequency == 0:\n",
        "        print(trainer.step)\n",
        "        loss_history.append(metrics['loss'])\n",
        "\n",
        "        trainer.save_checkpoint()\n",
        "        trainer.average_checkpoints(out_tag='avg')\n",
        "        trainer.load_checkpoint(tag='avg')\n",
        "        err = trainer.evaluate_classification_error(\n",
        "            X_train,\n",
        "            y_train,\n",
        "            device=device,\n",
        "            batch_size=128)\n",
        "        \n",
        "        train_acc.append(err)\n",
        "        err = trainer.evaluate_classification_error(\n",
        "            X_val,\n",
        "            y_val,\n",
        "            device=device,\n",
        "            batch_size=128)\n",
        "        \n",
        "        if err < best_val_err:\n",
        "            best_val_err = err\n",
        "            best_step = trainer.step\n",
        "            trainer.save_checkpoint(tag='best')\n",
        "        \n",
        "        err_history.append(err)\n",
        "        trainer.load_checkpoint()  # last\n",
        "        trainer.remove_old_temp_checkpoints()\n",
        "\n",
        "        '''\n",
        "        clear_output(True)\n",
        "        plt.figure(figsize=[12, 6])\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(loss_history)\n",
        "        plt.grid()\n",
        "        plt.subplot(1,2,2)\n",
        "        plt.plot(err_history)\n",
        "        plt.grid()\n",
        "        plt.show()\n",
        "        '''\n",
        "\n",
        "        print(\"Loss %.5f\" % (metrics['loss']))\n",
        "        print(\"Val Error Rate: %0.5f\" % (err))\n",
        "        \n",
        "    if trainer.step > best_step + early_stopping_rounds:\n",
        "        print('BREAK. There is no improvement for {} steps'.format(early_stopping_rounds))\n",
        "        print(\"Best step: \", best_step)\n",
        "        print(\"Best Val Error Rate: %0.5f\" % (best_val_err))\n",
        "        break"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_50.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_best.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_50.pth\n",
            "Loss 0.56056\n",
            "Val Error Rate: 0.24704\n",
            "100\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_100.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_best.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_100.pth\n",
            "Loss 0.52456\n",
            "Val Error Rate: 0.24474\n",
            "150\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_150.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_best.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_150.pth\n",
            "Loss 0.47018\n",
            "Val Error Rate: 0.23998\n",
            "200\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_200.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_best.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_200.pth\n",
            "Loss 0.44529\n",
            "Val Error Rate: 0.21941\n",
            "250\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_250.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_best.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_250.pth\n",
            "Loss 0.44295\n",
            "Val Error Rate: 0.19223\n",
            "300\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_300.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_best.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_300.pth\n",
            "Loss 0.44641\n",
            "Val Error Rate: 0.18655\n",
            "350\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_350.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_best.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_350.pth\n",
            "Loss 0.41809\n",
            "Val Error Rate: 0.15446\n",
            "400\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_400.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_best.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_400.pth\n",
            "Loss 0.41110\n",
            "Val Error Rate: 0.15369\n",
            "450\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_450.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_450.pth\n",
            "Loss 0.42355\n",
            "Val Error Rate: 0.15369\n",
            "500\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_500.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_best.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_500.pth\n",
            "Loss 0.41955\n",
            "Val Error Rate: 0.15308\n",
            "550\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_550.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_best.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_550.pth\n",
            "Loss 0.39422\n",
            "Val Error Rate: 0.15200\n",
            "600\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_600.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_600.pth\n",
            "Loss 0.35698\n",
            "Val Error Rate: 0.15446\n",
            "650\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_650.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_650.pth\n",
            "Loss 0.36887\n",
            "Val Error Rate: 0.15354\n",
            "700\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_700.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_700.pth\n",
            "Loss 0.37008\n",
            "Val Error Rate: 0.15385\n",
            "750\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_750.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_750.pth\n",
            "Loss 0.39844\n",
            "Val Error Rate: 0.15323\n",
            "800\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_800.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_800.pth\n",
            "Loss 0.37643\n",
            "Val Error Rate: 0.15231\n",
            "850\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_850.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_850.pth\n",
            "Loss 0.36940\n",
            "Val Error Rate: 0.15216\n",
            "900\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_900.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_best.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_900.pth\n",
            "Loss 0.37501\n",
            "Val Error Rate: 0.15062\n",
            "950\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_950.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_best.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_950.pth\n",
            "Loss 0.34340\n",
            "Val Error Rate: 0.14985\n",
            "1000\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_1000.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_best.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_1000.pth\n",
            "Loss 0.34617\n",
            "Val Error Rate: 0.14955\n",
            "1050\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_1050.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_1050.pth\n",
            "Loss 0.34598\n",
            "Val Error Rate: 0.15078\n",
            "1100\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_1100.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_best.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_1100.pth\n",
            "Loss 0.35979\n",
            "Val Error Rate: 0.14893\n",
            "1150\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_1150.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_1150.pth\n",
            "Loss 0.36507\n",
            "Val Error Rate: 0.15277\n",
            "1200\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_1200.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_1200.pth\n",
            "Loss 0.37642\n",
            "Val Error Rate: 0.15216\n",
            "1250\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_1250.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_1250.pth\n",
            "Loss 0.33911\n",
            "Val Error Rate: 0.15292\n",
            "1300\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_1300.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_1300.pth\n",
            "Loss 0.34562\n",
            "Val Error Rate: 0.15001\n",
            "1350\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_1350.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_1350.pth\n",
            "Loss 0.35232\n",
            "Val Error Rate: 0.15108\n",
            "1400\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_1400.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_1400.pth\n",
            "Loss 0.30281\n",
            "Val Error Rate: 0.15154\n",
            "1450\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_1450.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_1450.pth\n",
            "Loss 0.33684\n",
            "Val Error Rate: 0.15093\n",
            "1500\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_1500.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_1500.pth\n",
            "Loss 0.34341\n",
            "Val Error Rate: 0.14893\n",
            "1550\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_1550.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_best.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_1550.pth\n",
            "Loss 0.31153\n",
            "Val Error Rate: 0.14878\n",
            "1600\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_1600.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_1600.pth\n",
            "Loss 0.33113\n",
            "Val Error Rate: 0.14878\n",
            "1650\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_1650.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_1650.pth\n",
            "Loss 0.31728\n",
            "Val Error Rate: 0.14955\n",
            "1700\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_1700.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_1700.pth\n",
            "Loss 0.31838\n",
            "Val Error Rate: 0.15062\n",
            "1750\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_1750.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_1750.pth\n",
            "Loss 0.34600\n",
            "Val Error Rate: 0.15108\n",
            "1800\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_1800.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_1800.pth\n",
            "Loss 0.36216\n",
            "Val Error Rate: 0.15154\n",
            "1850\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_1850.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_1850.pth\n",
            "Loss 0.34987\n",
            "Val Error Rate: 0.15139\n",
            "1900\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_1900.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_best.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_1900.pth\n",
            "Loss 0.33769\n",
            "Val Error Rate: 0.14817\n",
            "1950\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_1950.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_best.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_1950.pth\n",
            "Loss 0.33025\n",
            "Val Error Rate: 0.14694\n",
            "2000\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_2000.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_2000.pth\n",
            "Loss 0.33669\n",
            "Val Error Rate: 0.14832\n",
            "2050\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_2050.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_2050.pth\n",
            "Loss 0.31640\n",
            "Val Error Rate: 0.14832\n",
            "2100\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_2100.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_2100.pth\n",
            "Loss 0.34419\n",
            "Val Error Rate: 0.14863\n",
            "2150\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_2150.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_2150.pth\n",
            "Loss 0.32624\n",
            "Val Error Rate: 0.14847\n",
            "2200\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_2200.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_2200.pth\n",
            "Loss 0.30240\n",
            "Val Error Rate: 0.14924\n",
            "2250\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_2250.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_2250.pth\n",
            "Loss 0.32948\n",
            "Val Error Rate: 0.14924\n",
            "2300\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_2300.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_2300.pth\n",
            "Loss 0.31060\n",
            "Val Error Rate: 0.14863\n",
            "2350\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_2350.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_2350.pth\n",
            "Loss 0.29942\n",
            "Val Error Rate: 0.14847\n",
            "2400\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_2400.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_2400.pth\n",
            "Loss 0.28047\n",
            "Val Error Rate: 0.14924\n",
            "2450\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_2450.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_2450.pth\n",
            "Loss 0.30489\n",
            "Val Error Rate: 0.14832\n",
            "2500\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_2500.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_2500.pth\n",
            "Loss 0.31785\n",
            "Val Error Rate: 0.14817\n",
            "2550\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_2550.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_2550.pth\n",
            "Loss 0.29941\n",
            "Val Error Rate: 0.14817\n",
            "2600\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_2600.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_2600.pth\n",
            "Loss 0.32665\n",
            "Val Error Rate: 0.14740\n",
            "2650\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_2650.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_2650.pth\n",
            "Loss 0.39781\n",
            "Val Error Rate: 0.14724\n",
            "2700\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_2700.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_2700.pth\n",
            "Loss 0.31279\n",
            "Val Error Rate: 0.14740\n",
            "2750\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_2750.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_2750.pth\n",
            "Loss 0.28518\n",
            "Val Error Rate: 0.14709\n",
            "2800\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_2800.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_2800.pth\n",
            "Loss 0.31996\n",
            "Val Error Rate: 0.14786\n",
            "2850\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_2850.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_2850.pth\n",
            "Loss 0.30850\n",
            "Val Error Rate: 0.14817\n",
            "2900\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_2900.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_2900.pth\n",
            "Loss 0.32772\n",
            "Val Error Rate: 0.14832\n",
            "2950\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_2950.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_2950.pth\n",
            "Loss 0.30005\n",
            "Val Error Rate: 0.14832\n",
            "3000\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_3000.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_3000.pth\n",
            "Loss 0.30696\n",
            "Val Error Rate: 0.14801\n",
            "3050\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_3050.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_3050.pth\n",
            "Loss 0.30053\n",
            "Val Error Rate: 0.14801\n",
            "3100\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_3100.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_3100.pth\n",
            "Loss 0.30750\n",
            "Val Error Rate: 0.14893\n",
            "3150\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_3150.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_3150.pth\n",
            "Loss 0.32625\n",
            "Val Error Rate: 0.14955\n",
            "3200\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_3200.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_3200.pth\n",
            "Loss 0.26264\n",
            "Val Error Rate: 0.14847\n",
            "3250\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_3250.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_3250.pth\n",
            "Loss 0.30064\n",
            "Val Error Rate: 0.14740\n",
            "3300\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_3300.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_3300.pth\n",
            "Loss 0.30579\n",
            "Val Error Rate: 0.14924\n",
            "3350\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_3350.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_3350.pth\n",
            "Loss 0.32370\n",
            "Val Error Rate: 0.14817\n",
            "3400\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_3400.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_3400.pth\n",
            "Loss 0.30417\n",
            "Val Error Rate: 0.14878\n",
            "3450\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_3450.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_3450.pth\n",
            "Loss 0.29355\n",
            "Val Error Rate: 0.14801\n",
            "3500\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_3500.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_3500.pth\n",
            "Loss 0.31467\n",
            "Val Error Rate: 0.14724\n",
            "3550\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_3550.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_3550.pth\n",
            "Loss 0.32287\n",
            "Val Error Rate: 0.14740\n",
            "3600\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_3600.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_3600.pth\n",
            "Loss 0.27932\n",
            "Val Error Rate: 0.14832\n",
            "3650\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_3650.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_3650.pth\n",
            "Loss 0.26780\n",
            "Val Error Rate: 0.14893\n",
            "3700\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_3700.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_3700.pth\n",
            "Loss 0.30247\n",
            "Val Error Rate: 0.14970\n",
            "3750\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_3750.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_3750.pth\n",
            "Loss 0.30720\n",
            "Val Error Rate: 0.14924\n",
            "3800\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_3800.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_3800.pth\n",
            "Loss 0.32261\n",
            "Val Error Rate: 0.15047\n",
            "3850\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_3850.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_3850.pth\n",
            "Loss 0.30069\n",
            "Val Error Rate: 0.15016\n",
            "3900\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_3900.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_3900.pth\n",
            "Loss 0.33884\n",
            "Val Error Rate: 0.14955\n",
            "3950\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_3950.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_3950.pth\n",
            "Loss 0.28378\n",
            "Val Error Rate: 0.14970\n",
            "4000\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_4000.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_4000.pth\n",
            "Loss 0.29261\n",
            "Val Error Rate: 0.15062\n",
            "4050\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_4050.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_4050.pth\n",
            "Loss 0.28517\n",
            "Val Error Rate: 0.15124\n",
            "4100\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_4100.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_4100.pth\n",
            "Loss 0.29829\n",
            "Val Error Rate: 0.15047\n",
            "4150\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_4150.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_4150.pth\n",
            "Loss 0.30688\n",
            "Val Error Rate: 0.15124\n",
            "4200\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_4200.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_4200.pth\n",
            "Loss 0.33744\n",
            "Val Error Rate: 0.14724\n",
            "4250\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_4250.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_4250.pth\n",
            "Loss 0.28437\n",
            "Val Error Rate: 0.15047\n",
            "4300\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_4300.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_4300.pth\n",
            "Loss 0.31573\n",
            "Val Error Rate: 0.15031\n",
            "4350\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_4350.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_4350.pth\n",
            "Loss 0.31632\n",
            "Val Error Rate: 0.15246\n",
            "4400\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_4400.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_4400.pth\n",
            "Loss 0.30491\n",
            "Val Error Rate: 0.15200\n",
            "4450\n",
            "Saved logs/node_adult_1618788365_extra_2/checkpoint_temp_4450.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_avg.pth\n",
            "Loaded logs/node_adult_1618788365_extra_2/checkpoint_temp_4450.pth\n",
            "Loss 0.29097\n",
            "Val Error Rate: 0.15154\n",
            "BREAK. There is no improvement for 2500 steps\n",
            "Best step:  1950\n",
            "Best Val Error Rate: 0.14694\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mnl0PNIUz0b"
      },
      "source": [
        "train_acc = pd.Series(train_acc, index=[i for i in range(89)])\n",
        "val_acc = pd.Series(err_history, index=[i for i in range(89)])\n",
        "\n",
        "train_loss = pd.Series(loss_history, index=[i for i in range(89)])"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWxD-VCuySG0",
        "outputId": "f4313f55-3636-4db9-cc66-e538cebfd28e"
      },
      "source": [
        "1 - trainer.evaluate_classification_error(\n",
        "            X_val,\n",
        "            y_val,\n",
        "            device=device,\n",
        ")"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8507600184246891"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "ZwQuejuDwOuq",
        "outputId": "3ae68a29-724c-4a67-fc98-7f6fc2d15303"
      },
      "source": [
        "df = pd.concat([train_acc, val_acc], axis=1, keys=['NODE Training Accuracy', 'NODE Test Accuracy'])\n",
        "df = df.reindex(range(df.index[-1]))\n",
        "df = 1-df\n",
        "df.to_csv('node.csv')\n",
        "df.plot()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc812639c90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6yFojv9OqLC"
      },
      "source": [
        "\n",
        "##Hyperparameter optimization with hyperopt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTh5c8DJAqMx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "c8469781-ee05-4ea5-cf30-5243eb5415ab"
      },
      "source": [
        "!pip install hyperopt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (0.1.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt) (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from hyperopt) (4.28.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt) (2.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.17.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.12.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt) (3.10.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt) (4.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxoyRBZJBipC"
      },
      "source": [
        "from hyperopt import fmin, hp, STATUS_OK, tpe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFYQOmd8EGe5"
      },
      "source": [
        "def opt_fn(search_space):\n",
        "  print(search_space)\n",
        "  best_val_err = 1.0\n",
        "  best_step = 0\n",
        "  early_stopping_rounds = 2500\n",
        "  report_frequency = 1000\n",
        "  experiment_name = 'debug' # this bypasses some code that will be executed each time otherwise\n",
        "  \n",
        "  model = nn.Sequential(\n",
        "      lib.DenseBlock(num_features,\n",
        "                     layer_dim=int(search_space['layer_dim']),\n",
        "                     num_layers=int(search_space['num_layers']),\n",
        "                     tree_dim=num_classes,\n",
        "                     flatten_output=False,\n",
        "                     depth=int(search_space['depth']),\n",
        "                     choice_function=lib.entmax15,\n",
        "                     bin_function=lib.entmoid15),\n",
        "      lib.Lambda(lambda x: x[..., :num_classes].mean(dim=-2)),\n",
        "    ).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    res = model(torch.as_tensor(X_train[:2000], device=device))\n",
        "    # trigger data-aware init\n",
        "\n",
        "  trainer = lib.Trainer(\n",
        "    model=model, loss_function=F.cross_entropy,\n",
        "    experiment_name=experiment_name,\n",
        "    warm_start=False,\n",
        "    Optimizer=QHAdam,\n",
        "    optimizer_params=dict(nus=(0.7, 1.0), betas=(0.95, 0.998)),\n",
        "    verbose=True,\n",
        "    n_last_checkpoints=5\n",
        "  )\n",
        "\n",
        "  for batch in lib.iterate_minibatches(X_train,\n",
        "                                     y_train,\n",
        "                                     batch_size=512, \n",
        "                                     shuffle=True,\n",
        "                                     epochs=float('inf')):\n",
        "    \n",
        "    metrics = trainer.train_on_batch(*batch, device=device)\n",
        "    \n",
        "\n",
        "    if trainer.step % report_frequency == 0:\n",
        "          err = trainer.evaluate_classification_error(\n",
        "              X_val,\n",
        "              y_val,\n",
        "              device=device,\n",
        "              batch_size=64)\n",
        "        \n",
        "          if err < best_val_err:\n",
        "              best_val_err = err\n",
        "              best_step = trainer.step\n",
        "\n",
        "          print(\"Loss %.5f\" % (metrics['loss']))\n",
        "          print(\"Val Error Rate: %0.5f\" % (err))\n",
        "        \n",
        "    if trainer.step > best_step + early_stopping_rounds:\n",
        "          opt_metric = best_val_err\n",
        "          break\n",
        "          \n",
        "  return {'loss': opt_metric, 'status': STATUS_OK}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "te_Ave7AFOCB"
      },
      "source": [
        "search_space = {'layer_dim': hp.quniform('layer_dim', 100, 1200, 100),\n",
        "                'num_layers': hp.quniform('num_layers', 1, 4, 1),\n",
        "                'depth': hp.quniform('depth', 2, 7, 1)\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyFx7p4vHl6k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "be054ae0-8a0a-448b-c712-3bf5633e7e6f"
      },
      "source": [
        "best = fmin(fn=opt_fn, \n",
        "            space=search_space, \n",
        "            algo=tpe.suggest, \n",
        "            max_evals=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'depth': 5.0, 'layer_dim': 400.0, 'num_layers': 1.0}\n",
            "Loss 0.49489\n",
            "Val Error Rate: 0.19752\n",
            "Loss 0.37428\n",
            "Val Error Rate: 0.18474\n",
            "Loss 0.36075\n",
            "Val Error Rate: 0.18315\n",
            "Loss 0.34080\n",
            "Val Error Rate: 0.14359\n",
            "Loss 0.32484\n",
            "Val Error Rate: 0.14384\n",
            "Loss 0.33885\n",
            "Val Error Rate: 0.14310\n",
            "Loss 0.33447\n",
            "Val Error Rate: 0.14237\n",
            "Loss 0.32657\n",
            "Val Error Rate: 0.14175\n",
            "Loss 0.28023\n",
            "Val Error Rate: 0.14040\n",
            "Loss 0.30521\n",
            "Val Error Rate: 0.13905\n",
            "Loss 0.29295\n",
            "Val Error Rate: 0.14040\n",
            "Loss 0.31161\n",
            "Val Error Rate: 0.14040\n",
            "{'depth': 3.0, 'layer_dim': 400.0, 'num_layers': 3.0}\n",
            "Loss 0.34179\n",
            "Val Error Rate: 0.13856\n",
            "Loss 0.29840\n",
            "Val Error Rate: 0.13192\n",
            "Loss 0.32886\n",
            "Val Error Rate: 0.13266\n",
            "Loss 0.30286\n",
            "Val Error Rate: 0.13070\n",
            "Loss 0.27480\n",
            "Val Error Rate: 0.13291\n",
            "Loss 0.27905\n",
            "Val Error Rate: 0.13045\n",
            "Loss 0.27075\n",
            "Val Error Rate: 0.12947\n",
            "Loss 0.20901\n",
            "Val Error Rate: 0.12947\n",
            "Loss 0.26313\n",
            "Val Error Rate: 0.13045\n",
            "{'depth': 2.0, 'layer_dim': 500.0, 'num_layers': 1.0}\n",
            "Loss 0.53569\n",
            "Val Error Rate: 0.24076\n",
            "Loss 0.45835\n",
            "Val Error Rate: 0.18438\n",
            "Loss 0.40637\n",
            "Val Error Rate: 0.18327\n",
            "Loss 0.40168\n",
            "Val Error Rate: 0.18327\n",
            "Loss 0.31934\n",
            "Val Error Rate: 0.15416\n",
            "Loss 0.35697\n",
            "Val Error Rate: 0.14507\n",
            "Loss 0.33251\n",
            "Val Error Rate: 0.14323\n",
            "Loss 0.31276\n",
            "Val Error Rate: 0.14396\n",
            "Loss 0.27985\n",
            "Val Error Rate: 0.14310\n",
            "Loss 0.31101\n",
            "Val Error Rate: 0.14187\n",
            "Loss 0.31328\n",
            "Val Error Rate: 0.14151\n",
            "Loss 0.28255\n",
            "Val Error Rate: 0.14089\n",
            "Loss 0.33383\n",
            "Val Error Rate: 0.14052\n",
            "Loss 0.32313\n",
            "Val Error Rate: 0.14052\n",
            "Loss 0.33253\n",
            "Val Error Rate: 0.14052\n",
            "{'depth': 6.0, 'layer_dim': 400.0, 'num_layers': 3.0}\n",
            "Loss 0.33014\n",
            "Val Error Rate: 0.13573\n",
            "Loss 0.27362\n",
            "Val Error Rate: 0.13328\n",
            "Loss 0.23516\n",
            "Val Error Rate: 0.12750\n",
            "Loss 0.27629\n",
            "Val Error Rate: 0.12554\n",
            "Loss 0.28627\n",
            "Val Error Rate: 0.12713\n",
            "Loss 0.24728\n",
            "Val Error Rate: 0.12689\n",
            "{'depth': 4.0, 'layer_dim': 100.0, 'num_layers': 3.0}\n",
            "Loss 0.39005\n",
            "Val Error Rate: 0.14249\n",
            "Loss 0.30375\n",
            "Val Error Rate: 0.13745\n",
            "Loss 0.31932\n",
            "Val Error Rate: 0.13536\n",
            "Loss 0.29362\n",
            "Val Error Rate: 0.13463\n",
            "Loss 0.31612\n",
            "Val Error Rate: 0.13377\n",
            "Loss 0.35316\n",
            "Val Error Rate: 0.13549\n",
            "Loss 0.26988\n",
            "Val Error Rate: 0.13377\n",
            "{'depth': 6.0, 'layer_dim': 300.0, 'num_layers': 2.0}\n",
            "Loss 0.37065\n",
            "Val Error Rate: 0.14384\n",
            "Loss 0.32502\n",
            "Val Error Rate: 0.13979\n",
            "Loss 0.28431\n",
            "Val Error Rate: 0.13782\n",
            "Loss 0.30459\n",
            "Val Error Rate: 0.13586\n",
            "Loss 0.29549\n",
            "Val Error Rate: 0.13536\n",
            "Loss 0.29964\n",
            "Val Error Rate: 0.13487\n",
            "Loss 0.26108\n",
            "Val Error Rate: 0.13364\n",
            "Loss 0.26823\n",
            "Val Error Rate: 0.13278\n",
            "Loss 0.27884\n",
            "Val Error Rate: 0.13266\n",
            "Loss 0.29364\n",
            "Val Error Rate: 0.13205\n",
            "Loss 0.27758\n",
            "Val Error Rate: 0.13278\n",
            "Loss 0.24705\n",
            "Val Error Rate: 0.13180\n",
            "Loss 0.25023\n",
            "Val Error Rate: 0.13045\n",
            "Loss 0.26575\n",
            "Val Error Rate: 0.13070\n",
            "Loss 0.24899\n",
            "Val Error Rate: 0.13156\n",
            "{'depth': 3.0, 'layer_dim': 100.0, 'num_layers': 1.0}\n",
            "Loss 0.46818\n",
            "Val Error Rate: 0.24076\n",
            "Loss 0.44487\n",
            "Val Error Rate: 0.18401\n",
            "Loss 0.41560\n",
            "Val Error Rate: 0.18450\n",
            "Loss 0.34384\n",
            "Val Error Rate: 0.18401\n",
            "{'depth': 3.0, 'layer_dim': 1000.0, 'num_layers': 2.0}\n",
            "Loss 0.36530\n",
            "Val Error Rate: 0.14187\n",
            "Loss 0.31448\n",
            "Val Error Rate: 0.13917\n",
            "Loss 0.30586\n",
            "Val Error Rate: 0.13672\n",
            "Loss 0.29058\n",
            "Val Error Rate: 0.13635\n",
            "Loss 0.29121\n",
            "Val Error Rate: 0.13647\n",
            "Loss 0.31437\n",
            "Val Error Rate: 0.13487\n",
            "Loss 0.29079\n",
            "Val Error Rate: 0.13549\n",
            "Loss 0.27752\n",
            "Val Error Rate: 0.13389\n",
            "Loss 0.26226\n",
            "Val Error Rate: 0.13401\n",
            "Loss 0.28565\n",
            "Val Error Rate: 0.13573\n",
            "{'depth': 7.0, 'layer_dim': 600.0, 'num_layers': 3.0}\n",
            "Loss 0.33907\n",
            "Val Error Rate: 0.13868\n",
            "Loss 0.29036\n",
            "Val Error Rate: 0.13192\n",
            "Loss 0.29982\n",
            "Val Error Rate: 0.12689\n",
            "Loss 0.25287\n",
            "Val Error Rate: 0.12849\n",
            "  8%|▊         | 8/100 [1:36:57<12:07:58, 474.77s/it, best loss: 0.12553740326741186]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-722b61e540af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             max_evals=100)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    405\u001b[0m                     show_progressbar=show_progressbar)\n\u001b[1;32m    406\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    225\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                         \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    842\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 844\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-5f15e237071e>\u001b[0m in \u001b[0;36mopt_fn\u001b[0;34m(search_space)\u001b[0m\n\u001b[1;32m     39\u001b[0m                                      epochs=float('inf')):\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/node/lib/trainer.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, device, *batch)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ysr44cQI1PU"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}